---

services: # Этот ключ 'services' должен начинаться с левого края
  verba: # Это имя сервиса, отступ 2 пробела
    build:
      context: ./
      dockerfile: Dockerfile
    ports:
      - 8000:8000
    environment:
      - WEAVIATE_URL_VERBA=http://weaviate:8080
      - OPENAI_API_KEY=$OPENAI_API_KEY
      - COHERE_API_KEY=$COHERE_API_KEY
      - OLLAMA_URL=http://ollama:11434 # Обновили, чтобы ссылаться на сервис 'ollama'
      - OLLAMA_MODEL=$OLLAMA_MODEL
      - OLLAMA_EMBED_MODEL=$OLLAMA_EMBED_MODEL
      - UNSTRUCTURED_API_KEY=$UNSTRUCTURED_API_KEY
      - UNSTRUCTURED_API_URL=$UNSTRUCTURED_API_URL
      - GITHUB_TOKEN=$GITHUB_TOKEN
    volumes:
      - ./data:/data/
    depends_on:
      weaviate:
        condition: service_healthy
      ollama: # Добавили зависимость от сервиса ollama
        condition: service_healthy
    healthcheck:
      test: wget --no-verbose --tries=3 --spider http://localhost:8000 || exit 1
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 10s
    networks:
      - ollama-docker
    # УБЕДИТЕСЬ, что здесь НЕТ строки extra_hosts для ollamahost. Она больше не нужна.


  weaviate: # Это имя сервиса, отступ 2 пробела
    command:
      - --host
      - 0.0.0.0
      - --port
      - '8080'
      - --scheme
      - http
    image: semitechnologies/weaviate:1.25.10
    ports:
      - 8080:8080
      - 3000:8080
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    healthcheck:
      test: wget --no-verbose --tries=3 --spider http://localhost:8080/v1/.well-known/ready || exit 1
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 10s
    environment:
      OPENAI_APIKEY: $OPENAI_API_KEY
      COHERE_APIKEY: $COHERE_API_KEY
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      ENABLE_MODULES: 'e'
      CLUSTER_HOSTNAME: 'node1'
    networks:
      - ollama-docker

  ollama: # <--- ЭТА СЕКЦИЯ ДОЛЖНА НАЧИНАТЬСЯ С ОТСТУПА В 2 ПРОБЕЛА (как verba и weaviate)
    image: ollama/ollama:latest
    ports:
      - 11434:11434 # Изменено, чтобы Ollama была доступна по стандартному порту
    volumes:
      - ollama_data:/root/.ollama # Создали новый том для сохранения моделей Ollama
      # - .:/code # Эту строку можно закомментировать/удалить, если она не нужна
      # - ./ollama/ollama:/root/.ollama # Если вы использовали этот путь, проверьте, что он ведет к данным моделей
    container_name: ollama # Устанавливаем имя контейнера для удобства
    pull_policy: always
    tty: true
    restart: always
    environment:
      - OLLAMA_KEEP_ALIVE=24h
      - OLLAMA_HOST=0.0.0.0
    healthcheck: # Добавлен Healthcheck для Ollama
      test: ["CMD", "ollama", "list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - ollama-docker

volumes: # Этот ключ 'volumes' должен начинаться с левого края
  weaviate_data: {}
  ollama_data: {} # Добавлен новый том для Ollama

networks: # Этот ключ 'networks' должен начинаться с левого края
  ollama-docker:
    external: false  
...























# Weaviate configuration
# WEAVIATE_URL_VERBA=http://weaviate:8080 # This is correct for Docker Compose
WEAVIATE_URL_VERBA=http://weaviate:8080
# WEAVIATE_API_KEY_VERBA= # Uncomment and set if you have an API key for Weaviate
AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED="true"

# Disable EmbeddedDB for Windows (and for Docker Compose on Linux this is not used)
# PERSISTENCE_DATA_PATH="./verba-data"

# Ollama configuration
# Ollama is running directly on the host machine, so containers access it via host.docker.internal
OLLAMA_URL=http://172.17.0.1:11434
OLLAMA_MODEL=deepseek-r1
OLLAMA_EMBED_MODEL=nomic-embed-text
DEFAULT_DEPLOYMENT=Docker

# Optional: OpenAI, Cohere, GitHub, Unstructured API keys if you plan to use them
# OPENAI_API_KEY=
# COHERE_API_KEY=
# UNSTRUCTURED_API_KEY=
# UNSTRUCTURED_API_URL=
# GITHUB_TOKEN=






